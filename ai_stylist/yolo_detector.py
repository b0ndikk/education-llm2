#!/usr/bin/env python3
"""
üéØ YOLO –î–ï–¢–ï–ö–¢–û–† - –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï –û–î–ï–ñ–î–´
"""

from ultralytics import YOLO
import cv2
from PIL import Image
import numpy as np

class YOLODetector:
    def __init__(self):
        """YOLO –¥–µ—Ç–µ–∫—Ç–æ—Ä –æ–¥–µ–∂–¥—ã"""
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è YOLO...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º YOLOv8 —Å –ª—É—á—à–µ–π –¥–µ—Ç–µ–∫—Ü–∏–µ–π
        self.model = YOLO('yolov8m.pt')  # –°—Ä–µ–¥–Ω—è—è –º–æ–¥–µ–ª—å –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏/—Ç–æ—á–Ω–æ—Å—Ç–∏
        
        print("‚úÖ YOLO –∑–∞–≥—Ä—É–∂–µ–Ω!")
    
    def detect_clothing(self, image: Image.Image) -> dict:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –æ–¥–µ–∂–¥—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
        try:
            img_np = np.array(image)
            results = self.model(img_np, conf=0.3)  # –ë–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –æ—Ö–≤–∞—Ç–∞
            
            detections = []
            for result in results:
                for box in result.boxes:
                    class_id = int(box.cls[0])
                    confidence = float(box.conf[0])
                    bbox = box.xyxy[0].tolist()
                    
                    class_name = self.model.names[class_id]
                    
                    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –¥–ª—è –æ–¥–µ–∂–¥—ã –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                    if self._is_clothing_related(class_name, confidence):
                        # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                        bbox_area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
                        image_area = img_np.shape[1] * img_np.shape[0]
                        area_ratio = bbox_area / image_area
                        
                        detections.append({
                            'class_id': class_id,
                            'class_name': class_name,
                            'confidence': confidence,
                            'bbox': bbox,
                            'area_ratio': area_ratio,
                            'is_large': area_ratio > 0.3,
                            'center_x': (bbox[0] + bbox[2]) / 2 / img_np.shape[1],
                            'center_y': (bbox[1] + bbox[3]) / 2 / img_np.shape[0]
                        })
            
            # –ê–Ω–∞–ª–∏–∑ –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏
            composition = self._analyze_composition(detections, img_np.shape)
            
            return {
                'detections': detections,
                'total_items': len(detections),
                'composition': composition,
                'has_clothing': len([d for d in detections if self._is_direct_clothing(d['class_name'])]) > 0
            }
            
        except Exception as e:
            return {"error": f"YOLO –æ—à–∏–±–∫–∞: {str(e)}"}
    
    def _is_clothing_related(self, class_name: str, confidence: float) -> bool:
        """–†–ê–°–®–ò–†–ï–ù–ù–´–ô –§–ò–õ–¨–¢–† –î–õ–Ø –í–°–ï–ô –û–î–ï–ñ–î–´"""
        clothing_categories = [
        # –û–°–ù–û–í–ù–ê–Ø –û–î–ï–ñ–î–ê
        'person', 'tie', 
        
        # –û–ë–£–í–¨ (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ YOLO –∫–ª–∞—Å—Å–∞—Ö)
        'shoe', 'sneaker', 'boot', 
        
        # –°–£–ú–ö–ò –ò –†–Æ–ö–ó–ê–ö–ò
        'handbag', 'backpack', 'suitcase', 'purse',
        
        # –°–ü–û–†–¢–ò–í–ù–´–ô –ò–ù–í–ï–ù–¢–ê–†–¨ (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–µ–∂–¥—É)
        'sports ball', 'baseball bat', 'baseball glove', 
        'tennis racket', 'skateboard', 'surfboard',
        
        # –ê–ö–°–ï–°–°–£–ê–†–´
        'umbrella', 'hat', 'cap'
    ]
    
    # –î–ª—è person - –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥, —Ç–∞–∫ –∫–∞–∫ –Ω–∞ —á–µ–ª–æ–≤–µ–∫–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–¥–µ–∂–¥–∞
        if class_name == 'person':
            return confidence > 0.3
        else:
            return class_name in clothing_categories and confidence > 0.4
    
    def _is_direct_clothing(self, class_name: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ–±—ä–µ–∫—Ç –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –æ–¥–µ–∂–¥–æ–π"""
        direct_clothing = ['tie', 'handbag', 'backpack']
        return class_name in direct_clothing
    
    def _analyze_composition(self, detections: list, image_shape: tuple) -> dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–º–ø–æ–∑–∏—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if not detections:
            return {'dominant_region': 'center', 'layout': 'empty'}
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
        centers_x = [d['center_x'] for d in detections]
        centers_y = [d['center_y'] for d in detections]
        
        avg_x = np.mean(centers_x)
        avg_y = np.mean(centers_y)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â—É—é –æ–±–ª–∞—Å—Ç—å
        if avg_x < 0.33: 
            horizontal_pos = 'left'
        elif avg_x > 0.66: 
            horizontal_pos = 'right'
        else: 
            horizontal_pos = 'center'
            
        if avg_y < 0.33: 
            vertical_pos = 'top'
        elif avg_y > 0.66: 
            vertical_pos = 'bottom'
        else: 
            vertical_pos = 'middle'
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ –æ–±—ä–µ–∫—Ç–æ–≤
        large_objects = len([d for d in detections if d['is_large']])
        layout = 'focused' if large_objects > 0 else 'scattered'
        
        return {
            'dominant_region': f"{horizontal_pos}-{vertical_pos}",
            'layout': layout,
            'object_density': len(detections) / (image_shape[0] * image_shape[1] / 10000),
            'has_large_objects': large_objects > 0
        }