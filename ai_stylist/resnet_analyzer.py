#!/usr/bin/env python3
"""
üéØ RESNET –ê–ù–ê–õ–ò–ó–ê–¢–û–† - –¢–ï–ö–°–¢–£–†–ê –ò –¶–í–ï–¢
"""

import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import cv2

class ResNetAnalyzer:
    def __init__(self):
        """ResNet –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç—É—Ä –∏ —Ü–≤–µ—Ç–æ–≤"""
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ResNet...")
        
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é ResNet
        self.model = models.resnet50(pretrained=True)
        self.model.eval()
        self.model.to(self.device)
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã –¥–ª—è ResNet
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        # –ö–ª–∞—Å—Å—ã ImageNet –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.texture_classes = {
            # –¢–µ–∫—Å—Ç—É—Ä—ã –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã
            411: 'velvet', 412: 'wool', 413: 'silk', 414: 'cotton',
            415: 'linen', 416: 'denim', 417: 'leather', 418: 'fur',
            # –¶–≤–µ—Ç–∞ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            419: 'plaid', 420: 'striped', 421: 'polka dot', 422: 'floral'
        }
        
        print("‚úÖ ResNet –∑–∞–≥—Ä—É–∂–µ–Ω!")
    
    def analyze_image(self, image: Image.Image) -> dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç—É—Ä—É –∏ —Ü–≤–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ ResNet
            with torch.no_grad():
                inputs = self.transform(image).unsqueeze(0).to(self.device)
                outputs = self.model(inputs)
                probabilities = torch.softmax(outputs[0], dim=0)
            
            # –ù–∞—Ö–æ–¥–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–ª–∞—Å—Å—ã
            relevant_features = {}
            for class_id, class_name in self.texture_classes.items():
                if class_id < len(probabilities):
                    prob = probabilities[class_id].item()
                    if prob > 0.01:  # –ü–æ—Ä–æ–≥ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
                        relevant_features[class_name] = prob
            
            # –ê–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–∞
            color_analysis = self._analyze_colors(image)
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç—É—Ä—ã
            texture_analysis = self._analyze_texture(image)
            
            return {
                'texture_features': relevant_features,
                'color_analysis': color_analysis,
                'texture_complexity': texture_analysis,
                'deep_features': outputs[0][:100].tolist()  # –ü–µ—Ä–≤—ã–µ 100 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            }
            
        except Exception as e:
            return {"error": f"ResNet –æ—à–∏–±–∫–∞: {str(e)}"}
    
    def _analyze_colors(self, image: Image.Image) -> dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ —Ü–≤–µ—Ç–∞"""
        img_np = np.array(image)
        img_small = cv2.resize(img_np, (100, 100))
        pixels = img_small.reshape(-1, 3)
        
        # K-means –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏—Ö —Ü–≤–µ—Ç–æ–≤
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)
        _, labels, centers = cv2.kmeans(pixels.astype(np.float32), 5, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω–∞–∑–≤–∞–Ω–∏—è —Ü–≤–µ—Ç–æ–≤
        color_names = []
        for color in centers:
            color_names.append(self._rgb_to_color_name(color))
        
        return {
            'dominant_colors': color_names[:3],  # –¢–æ–ø-3 —Ü–≤–µ—Ç–∞
            'color_variance': np.var(pixels, axis=0).tolist(),
            'brightness': np.mean(pixels) / 255.0
        }
    
    def _analyze_texture(self, image: Image.Image) -> str:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç—É—Ä—ã"""
        img_np = np.array(image)
        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏—é –õ–∞–ø–ª–∞—Å–∏–∞–Ω–∞
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        if laplacian_var < 100: return "smooth"
        elif laplacian_var < 500: return "medium"
        else: return "complex"
    
    def _rgb_to_color_name(self, rgb: np.ndarray) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç RGB –≤ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ü–≤–µ—Ç–∞"""
        color_map = {
            'black': [0, 0, 0], 'white': [255, 255, 255],
            'red': [255, 0, 0], 'blue': [0, 0, 255],
            'green': [0, 255, 0], 'yellow': [255, 255, 0],
            'purple': [128, 0, 128], 'pink': [255, 192, 203],
            'brown': [165, 42, 42], 'gray': [128, 128, 128],
            'orange': [255, 165, 0], 'beige': [245, 245, 220]
        }
        
        min_distance = float('inf')
        closest_color = 'unknown'
        
        for name, ref_rgb in color_map.items():
            distance = np.linalg.norm(rgb - ref_rgb)
            if distance < min_distance:
                min_distance = distance
                closest_color = name
        
        return closest_color